{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revamp(X):\n",
    "    X_out = np.zeros(np.shape(X))\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[1])):\n",
    "            value = X[i][j]\n",
    "            if value < 5.0:\n",
    "                X_out[i][j] = 0 #'DARK'\n",
    "            elif value > 10.0:\n",
    "                X_out[i][j] = 2 #'LIGHT'\n",
    "            else:\n",
    "                X_out[i][j] = 1 #'GRAY'\n",
    "    return X_out\n",
    "#Summerised into 0,1,2 aka DARK, LIGHT, GRAY\n",
    "X_train_sum = revamp(X_train)\n",
    "X_test_sum = revamp(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNIST\n",
    "mnist = MNIST.MNISTData('MNIST_Light/*/*.png')\n",
    "train_features, test_features, train_labels, test_labels = mnist.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBC:\n",
    "    def __init__(self, nbr_classes, size, value_len):\n",
    "        self.nbr_classes = nbr_classes \n",
    "        self.size = size\n",
    "        self.value_len = value_len\n",
    "        self.prob = np.zeros(nbr_classes)\n",
    "        self.cond_prob = np.zeros((nbr_classes,size,value_len))\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for i in range(len(X)):\n",
    "            self.prob[y[i]] += 1\n",
    "            for j in range(len(X[1])):\n",
    "                self.cond_prob[y[i]][j][int(X[i][j])] += 1\n",
    "        for k in range(self.nbr_classes):\n",
    "            self.cond_prob[k] = self.cond_prob[k]/self.prob[k]\n",
    "        self.prob = self.prob/sum(self.prob)\n",
    "        \n",
    "    def prediction(self,X):\n",
    "        y = np.ones((len(X),self.nbr_classes))\n",
    "        pred = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            for j in range(self.nbr_classes):\n",
    "                for k in range(len(X[1])):\n",
    "                    y[i][j] *= self.cond_prob[j][k][int(X[i][k])]\n",
    "                y[i][j] *= self.prob[j]\n",
    "                if np.max(y[i]) == 0:\n",
    "                    pred[i] = 10\n",
    "                else:\n",
    "                    pred[i] = np.argmax(y[i])\n",
    "        return pred           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc_dig = NBC(10,len(X_train[1]),17)\n",
    "nbc_dig.fit(X_train,y_train)\n",
    "y_pred = nbc_dig.prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report NBC digits:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.51      0.68        49\n",
      "         1.0       0.94      0.51      0.66        63\n",
      "         2.0       0.92      0.75      0.83        44\n",
      "         3.0       0.95      0.52      0.67        67\n",
      "         4.0       0.97      0.61      0.75        57\n",
      "         5.0       1.00      0.75      0.86        52\n",
      "         6.0       1.00      0.69      0.82        49\n",
      "         7.0       0.83      0.56      0.67        52\n",
      "         8.0       0.65      0.55      0.60        51\n",
      "         9.0       0.81      0.52      0.63        56\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59       540\n",
      "   macro avg       0.82      0.54      0.65       540\n",
      "weighted avg       0.91      0.59      0.71       540\n",
      "\n",
      "\n",
      "Confusion matrix NBC digits:\n",
      "[[25  0  0  0  0  0  0  0  1  0 23]\n",
      " [ 0 32  0  0  1  0  0  0  3  3 24]\n",
      " [ 0  0 33  2  0  0  0  0  2  0  7]\n",
      " [ 0  0  3 35  0  0  0  0  5  4 20]\n",
      " [ 0  0  0  0 35  0  0  3  0  0 19]\n",
      " [ 0  1  0  0  0 39  0  1  0  0 11]\n",
      " [ 0  0  0  0  0  0 34  0  0  0 15]\n",
      " [ 0  0  0  0  0  0  0 29  0  0 23]\n",
      " [ 0  1  0  0  0  0  0  0 28  0 22]\n",
      " [ 0  0  0  0  0  0  0  2  4 29 21]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report NBC digits:\\n%s\\n\"\n",
    "          % (metrics.classification_report(y_test, y_pred)))\n",
    "print(\"Confusion matrix NBC digits:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits (summerised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc_dig2 = NBC(10,len(X_train_sum[1]),17)\n",
    "nbc_dig2.fit(X_train_sum,y_train)\n",
    "y_pred = nbc_dig2.prediction(X_test_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report NBC digits (summerised):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        49\n",
      "         1.0       0.80      0.81      0.80        63\n",
      "         2.0       0.85      0.89      0.87        44\n",
      "         3.0       0.95      0.88      0.91        67\n",
      "         4.0       0.93      0.89      0.91        57\n",
      "         5.0       0.88      0.96      0.92        52\n",
      "         6.0       0.98      0.96      0.97        49\n",
      "         7.0       0.94      0.92      0.93        52\n",
      "         8.0       0.79      0.82      0.81        51\n",
      "         9.0       0.87      0.84      0.85        56\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89       540\n",
      "   macro avg       0.82      0.81      0.81       540\n",
      "weighted avg       0.90      0.89      0.89       540\n",
      "\n",
      "\n",
      "Confusion matrix NBC digits (summerised):\n",
      "[[45  0  0  0  0  3  0  0  0  0  1]\n",
      " [ 0 51  4  0  1  0  1  0  2  3  1]\n",
      " [ 0  1 39  0  0  0  0  0  3  1  0]\n",
      " [ 0  1  3 59  0  0  0  1  2  0  1]\n",
      " [ 0  1  0  0 51  0  0  2  1  0  2]\n",
      " [ 0  0  0  0  0 50  0  0  0  2  0]\n",
      " [ 0  2  0  0  0  0 47  0  0  0  0]\n",
      " [ 0  1  0  0  1  1  0 48  0  1  0]\n",
      " [ 0  7  0  1  0  1  0  0 42  0  0]\n",
      " [ 0  0  0  2  2  2  0  0  3 47  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report NBC digits (summerised):\\n%s\\n\"\n",
    "          % (metrics.classification_report(y_test, y_pred)))\n",
    "print(\"Confusion matrix NBC digits (summerised):\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc_mnist = NBC(10,len(train_features[1]),255)\n",
    "nbc_mnist.fit(train_features,train_labels)\n",
    "pred_labels = nbc_mnist.prediction(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report NBC MNIST_light:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.73      0.81       164\n",
      "         1.0       0.44      0.91      0.59       152\n",
      "         2.0       0.72      0.55      0.62       155\n",
      "         3.0       0.71      0.56      0.63       154\n",
      "         4.0       0.61      0.64      0.62       143\n",
      "         5.0       0.55      0.57      0.56       141\n",
      "         6.0       0.84      0.61      0.70       143\n",
      "         7.0       0.76      0.55      0.64       158\n",
      "         8.0       0.52      0.46      0.49       132\n",
      "         9.0       0.54      0.59      0.57       158\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62      1500\n",
      "   macro avg       0.60      0.56      0.57      1500\n",
      "weighted avg       0.66      0.62      0.63      1500\n",
      "\n",
      "\n",
      "Confusion matrix NBC MNIST_light:\n",
      "[[119   5   7   2   2  19   5   0   2   3   0]\n",
      " [  0 138   0   0   0   4   1   0   9   0   0]\n",
      " [  0  24  85   8   7   8   3   0  12   5   3]\n",
      " [  1  16  13  87   3  11   0   0  16   6   1]\n",
      " [  2  14   3   0  91   1   3   4   3  21   1]\n",
      " [  5  16   0  10  14  81   3   4   5   3   0]\n",
      " [  1  27   5   2   3   8  87   1   1   6   2]\n",
      " [  0  21   2   1   8   4   0  87   5  29   1]\n",
      " [  0  33   3  12   6  11   0   1  61   5   0]\n",
      " [  2  20   0   1  16   1   2  18   3  93   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report NBC MNIST_light:\\n%s\\n\"\n",
    "          % (metrics.classification_report(test_labels, pred_labels)))\n",
    "print(\"Confusion matrix NBC MNIST_light:\\n%s\" % metrics.confusion_matrix(test_labels, pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
